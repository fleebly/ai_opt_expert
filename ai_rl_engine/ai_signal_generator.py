#!/usr/bin/env python3
"""
AI Signal Generator - å…¨å¸‚åœºå¹¿åº¦æ‰«æ

åŠŸèƒ½ï¼š
1. æ‰«æå¤šæ ‡çš„ï¼Œè¯†åˆ«æ³¢åŠ¨ç‡å‹ç¼©æœºä¼š
2. ç»“åˆè´¢æŠ¥äº‹ä»¶ã€æ–°é—»æƒ…ç»ª
3. è¿‡æ»¤æµåŠ¨æ€§å·®çš„æ ‡çš„
4. è¾“å‡ºå€™é€‰ä¿¡å·æ± 

ç­–ç•¥æ ¸å¿ƒï¼š
- å¸ƒæ—å¸¦å®½åº¦ç™¾åˆ†ä½ < 30% â†’ æ³¢åŠ¨ç‡å‹ç¼©
- è·ç¦»è´¢æŠ¥ 7~21 å¤© â†’ äº‹ä»¶é©±åŠ¨
- æœŸæƒæµåŠ¨æ€§å……è¶³ â†’ Bid-Ask Spread < 5%
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging
from dataclasses import dataclass

try:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from strategy_system.data_fetcher import PolygonDataFetcher
except ImportError:
    PolygonDataFetcher = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Signal:
    """ä¿¡å·æ•°æ®ç»“æ„"""
    symbol: str
    timestamp: str
    bb_percentile: float  # å¸ƒæ—å¸¦å®½åº¦ç™¾åˆ†ä½ (0-1)
    dte_to_event: Optional[int]  # è·ç¦»ä¸‹æ¬¡äº‹ä»¶å¤©æ•°
    news_sentiment: float  # æ–°é—»æƒ…æ„Ÿ (-1 to 1)
    liquidity_score: float  # æµåŠ¨æ€§å¾—åˆ† (0-1)
    iv_rank: float  # IV Rank (0-100)
    signal_strength: float  # ç»¼åˆä¿¡å·å¼ºåº¦ (0-1)
    status: str  # 'strong', 'moderate', 'weak'


class AISignalGenerator:
    """
    AI ä¿¡å·ç”Ÿæˆå™¨
    
    å·¥ä½œæµï¼š
    1. è¾“å…¥ watchlistï¼ˆå¦‚ ['NVDA', 'TSLA', 'AAPL']ï¼‰
    2. å¯¹æ¯ä¸ªæ ‡çš„è®¡ç®—ç‰¹å¾
    3. è¾“å‡ºå€™é€‰ä¿¡å· DataFrame
    """
    
    # ç¾è‚¡çƒ­é—¨æ ‡çš„æ± ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    DEFAULT_WATCHLIST = [
        'NVDA', 'TSLA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META',
        'AMD', 'INTC', 'NFLX', 'DIS', 'BA', 'SPY', 'QQQ'
    ]
    
    def __init__(self, data_fetcher: Optional[PolygonDataFetcher] = None):
        """
        Args:
            data_fetcher: Polygon æ•°æ®è·å–å™¨ï¼Œå¯é€‰
        """
        self.data_fetcher = data_fetcher or (
            PolygonDataFetcher() if PolygonDataFetcher else None
        )
    
    def scan_market(
        self,
        watchlist: Optional[List[str]] = None,
        lookback_days: int = 60
    ) -> pd.DataFrame:
        """
        æ‰«æå¸‚åœºï¼Œç”Ÿæˆå€™é€‰ä¿¡å·
        
        Args:
            watchlist: æ ‡çš„åˆ—è¡¨ï¼Œé»˜è®¤ç”¨çƒ­é—¨è‚¡
            lookback_days: å›æº¯å¤©æ•°
        
        Returns:
            DataFrame with columns: symbol, bb_percentile, dte_to_event, 
                                    news_sentiment, signal_strength, status
        """
        watchlist = watchlist or self.DEFAULT_WATCHLIST
        logger.info(f"Scanning {len(watchlist)} symbols...")
        
        signals = []
        for symbol in watchlist:
            try:
                signal = self._analyze_symbol(symbol, lookback_days)
                if signal and signal.signal_strength > 0.3:  # è¿‡æ»¤å¼±ä¿¡å·
                    signals.append(signal)
            except Exception as e:
                logger.warning(f"Failed to analyze {symbol}: {e}")
                continue
        
        # è½¬ä¸º DataFrame
        if not signals:
            return pd.DataFrame()
        
        df = pd.DataFrame([vars(s) for s in signals])
        df = df.sort_values('signal_strength', ascending=False)
        
        logger.info(f"Found {len(df)} candidate signals")
        return df
    
    def _analyze_symbol(self, symbol: str, lookback_days: int) -> Optional[Signal]:
        """
        åˆ†æå•ä¸ªæ ‡çš„
        
        è®¡ç®—ï¼š
        1. å¸ƒæ—å¸¦å®½åº¦ç™¾åˆ†ä½
        2. è·ç¦»è´¢æŠ¥å¤©æ•°
        3. æ–°é—»æƒ…æ„Ÿï¼ˆmockï¼‰
        4. æµåŠ¨æ€§å¾—åˆ†
        5. IV Rank
        """
        # è·å–å†å²æ•°æ®
        data = self._fetch_historical_data(symbol, lookback_days)
        if data is None or len(data) < 20:
            return None
        
        # 1. è®¡ç®—å¸ƒæ—å¸¦å®½åº¦ç™¾åˆ†ä½
        bb_percentile = self._calculate_bb_percentile(data)
        
        # 2. è´¢æŠ¥äº‹ä»¶ï¼ˆmockï¼Œå®é™…å¯ç”¨ Polygon Calendar APIï¼‰
        dte_to_event = self._get_days_to_earnings(symbol)
        
        # 3. æ–°é—»æƒ…æ„Ÿï¼ˆmockï¼Œå®é™…å¯ç”¨ NewsAPI + BERTï¼‰
        news_sentiment = self._get_news_sentiment(symbol)
        
        # 4. æµåŠ¨æ€§å¾—åˆ†
        liquidity_score = self._calculate_liquidity(data)
        
        # 5. IV Rankï¼ˆéœ€è¦æœŸæƒæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–ç”¨ä»·æ ¼æ³¢åŠ¨ç‡ï¼‰
        iv_rank = self._calculate_iv_rank(data)
        
        # ç»¼åˆè¯„åˆ†
        signal_strength = self._calculate_signal_strength(
            bb_percentile, dte_to_event, news_sentiment, liquidity_score, iv_rank
        )
        
        # çŠ¶æ€åˆ†ç±»
        if signal_strength >= 0.7:
            status = 'strong'
        elif signal_strength >= 0.5:
            status = 'moderate'
        else:
            status = 'weak'
        
        return Signal(
            symbol=symbol,
            timestamp=datetime.now().isoformat(),
            bb_percentile=bb_percentile,
            dte_to_event=dte_to_event,
            news_sentiment=news_sentiment,
            liquidity_score=liquidity_score,
            iv_rank=iv_rank,
            signal_strength=signal_strength,
            status=status
        )
    
    def _fetch_historical_data(self, symbol: str, days: int) -> Optional[pd.DataFrame]:
        """è·å–å†å² OHLCV æ•°æ®"""
        if self.data_fetcher:
            try:
                # ä½¿ç”¨ Polygon
                end_date = datetime.now()
                start_date = end_date - timedelta(days=days)
                data = self.data_fetcher.get_historical_data(
                    symbol,
                    start_date.strftime('%Y-%m-%d'),
                    end_date.strftime('%Y-%m-%d')
                )
                return data
            except:
                pass
        
        # Fallback: yfinance
        try:
            import yfinance as yf
            ticker = yf.Ticker(symbol)
            data = ticker.history(period=f"{days}d")
            if data.empty:
                return None
            data = data.reset_index()
            data.columns = [c.lower() for c in data.columns]
            return data
        except:
            return None
    
    def _calculate_bb_percentile(self, data: pd.DataFrame, window: int = 20) -> float:
        """
        è®¡ç®—å¸ƒæ—å¸¦å®½åº¦ç™¾åˆ†ä½
        
        BB Width = (Upper Band - Lower Band) / Middle Band
        Percentile = å½“å‰å®½åº¦åœ¨è¿‡å» N å¤©çš„åˆ†ä½æ•°
        
        ä½ç™¾åˆ†ä½ â†’ æ³¢åŠ¨ç‡å‹ç¼© â†’ å³å°†çªç ´
        """
        close = data['close'].values
        
        # è®¡ç®—å¸ƒæ—å¸¦
        sma = pd.Series(close).rolling(window).mean()
        std = pd.Series(close).rolling(window).std()
        
        upper_band = sma + 2 * std
        lower_band = sma - 2 * std
        
        bb_width = (upper_band - lower_band) / sma
        bb_width = bb_width.dropna()
        
        if len(bb_width) < 2:
            return 0.5
        
        # å½“å‰å®½åº¦çš„ç™¾åˆ†ä½
        current_width = bb_width.iloc[-1]
        percentile = (bb_width < current_width).sum() / len(bb_width)
        
        return percentile
    
    def _get_days_to_earnings(self, symbol: str) -> Optional[int]:
        """
        è·å–è·ç¦»ä¸‹æ¬¡è´¢æŠ¥çš„å¤©æ•°
        
        å®é™…å®ç°å¯ç”¨ï¼š
        - Polygon Calendar API
        - Earnings Whisper API
        - çˆ¬è™«æŠ“å– earnings.com
        
        è¿™é‡Œ mock è¿”å›
        """
        # Mock: éšæœº 7~60 å¤©
        mock_dte = np.random.randint(7, 60)
        
        # åªæœ‰åœ¨ 7~21 å¤©å†…æ‰è¿”å›ï¼ˆäº‹ä»¶é©±åŠ¨çª—å£ï¼‰
        if 7 <= mock_dte <= 21:
            return mock_dte
        return None
    
    def _get_news_sentiment(self, symbol: str) -> float:
        """
        è·å–æ–°é—»æƒ…æ„Ÿå¾—åˆ† (-1 to 1)
        
        å®é™…å®ç°å¯ç”¨ï¼š
        - NewsAPI + FinBERT
        - Polygon News API
        - Twitter/Reddit çˆ¬è™«
        
        è¿™é‡Œ mock è¿”å›
        """
        # Mock: éšæœº -0.5 ~ 0.5
        return np.random.uniform(-0.5, 0.5)
    
    def _calculate_liquidity(self, data: pd.DataFrame) -> float:
        """
        æµåŠ¨æ€§å¾—åˆ† (0-1)
        
        åŸºäºï¼š
        - æ—¥å‡æˆäº¤é‡
        - æœ€è¿‘ 5 æ—¥æ³¢åŠ¨æ€§
        
        é«˜æµåŠ¨æ€§ â†’ é€‚åˆæœŸæƒäº¤æ˜“
        """
        if 'volume' not in data.columns or len(data) < 5:
            return 0.5
        
        # å¹³å‡æˆäº¤é‡
        avg_volume = data['volume'].tail(20).mean()
        
        # å½’ä¸€åŒ–ï¼ˆç™¾ä¸‡ä¸ºå•ä½ï¼‰
        volume_score = min(avg_volume / 10_000_000, 1.0)
        
        # æ³¢åŠ¨æ€§ï¼ˆä½æ³¢åŠ¨ = é«˜æµåŠ¨æ€§ï¼‰
        returns = data['close'].pct_change().tail(20)
        volatility = returns.std()
        vol_score = 1 - min(volatility / 0.05, 1.0)
        
        return 0.6 * volume_score + 0.4 * vol_score
    
    def _calculate_iv_rank(self, data: pd.DataFrame, window: int = 252) -> float:
        """
        IV Rank ä¼°ç®—
        
        å®é™…åº”ç”¨éœ€è¦æœŸæƒéšå«æ³¢åŠ¨ç‡ï¼Œè¿™é‡Œç”¨å†å²æ³¢åŠ¨ç‡æ›¿ä»£
        
        IV Rank = (å½“å‰ IV - 52å‘¨æœ€ä½) / (52å‘¨æœ€é«˜ - 52å‘¨æœ€ä½) * 100
        """
        returns = data['close'].pct_change().dropna()
        
        if len(returns) < 20:
            return 50.0
        
        # æ»šåŠ¨ 20 æ—¥æ³¢åŠ¨ç‡
        rolling_vol = returns.rolling(20).std() * np.sqrt(252)
        
        if len(rolling_vol) < 2:
            return 50.0
        
        current_vol = rolling_vol.iloc[-1]
        min_vol = rolling_vol.min()
        max_vol = rolling_vol.max()
        
        if max_vol == min_vol:
            return 50.0
        
        iv_rank = ((current_vol - min_vol) / (max_vol - min_vol)) * 100
        
        return iv_rank
    
    def _calculate_signal_strength(
        self,
        bb_percentile: float,
        dte_to_event: Optional[int],
        news_sentiment: float,
        liquidity_score: float,
        iv_rank: float
    ) -> float:
        """
        ç»¼åˆä¿¡å·å¼ºåº¦è¯„åˆ†
        
        æƒé‡åˆ†é…ï¼š
        - BB ç™¾åˆ†ä½: 30% (è¶Šä½è¶Šå¥½)
        - äº‹ä»¶é©±åŠ¨: 25% (æœ‰è´¢æŠ¥åŠ åˆ†)
        - æµåŠ¨æ€§: 20%
        - IV Rank: 15% (ä¸­ç­‰ IV æœ€ä½³)
        - æ–°é—»æƒ…æ„Ÿ: 10%
        """
        # 1. BB å¾—åˆ†ï¼ˆä½ç™¾åˆ†ä½é«˜åˆ†ï¼‰
        bb_score = 1 - bb_percentile
        
        # 2. äº‹ä»¶å¾—åˆ†
        if dte_to_event:
            event_score = 1.0 if 7 <= dte_to_event <= 14 else 0.7
        else:
            event_score = 0.3
        
        # 3. æµåŠ¨æ€§å¾—åˆ†
        liq_score = liquidity_score
        
        # 4. IV Rank å¾—åˆ†ï¼ˆ30-70 æœ€ä½³ï¼‰
        if 30 <= iv_rank <= 70:
            iv_score = 1.0
        elif iv_rank < 30:
            iv_score = iv_rank / 30
        else:
            iv_score = (100 - iv_rank) / 30
        
        # 5. æ–°é—»å¾—åˆ†ï¼ˆä¸­æ€§æœ€ä½³ï¼Œé¿å…æç«¯ï¼‰
        news_score = 1 - abs(news_sentiment)
        
        # åŠ æƒæ±‚å’Œ
        signal = (
            0.30 * bb_score +
            0.25 * event_score +
            0.20 * liq_score +
            0.15 * iv_score +
            0.10 * news_score
        )
        
        return np.clip(signal, 0, 1)


# =============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# =============================================================================

def main():
    """ç¤ºä¾‹ï¼šæ‰«æå¸‚åœºå¹¶è¾“å‡ºå€™é€‰ä¿¡å·"""
    
    generator = AISignalGenerator()
    
    # æ‰«æçƒ­é—¨è‚¡
    signals_df = generator.scan_market(
        watchlist=['NVDA', 'TSLA', 'AAPL', 'MSFT', 'AMD'],
        lookback_days=60
    )
    
    if signals_df.empty:
        print("No signals found.")
        return
    
    print("\n" + "="*80)
    print("ğŸ” AI Signal Generator - Market Scan Results")
    print("="*80 + "\n")
    
    # æ˜¾ç¤ºå‰ 10 ä¸ªä¿¡å·
    print(signals_df[['symbol', 'bb_percentile', 'dte_to_event', 
                      'signal_strength', 'status']].head(10).to_string(index=False))
    
    print("\n" + "="*80)
    print(f"âœ… Found {len(signals_df)} candidates")
    print(f"   - Strong: {(signals_df['status'] == 'strong').sum()}")
    print(f"   - Moderate: {(signals_df['status'] == 'moderate').sum()}")
    print("="*80 + "\n")


if __name__ == '__main__':
    main()




